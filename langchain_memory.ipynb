{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model = \"llama-3.3-70b-versatile\", temperature=0.0)\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion = RunnableWithMessageHistory(runnable=llm,\n",
    "    get_session_history=lambda session_id: memory.chat_memory,\n",
    "   \n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = config={'configurable':{'session_id':'unique_session_123'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conversion.invoke(\"Hi, my name is Azeem\", temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Azeem! It's nice to meet you. Is there something I can help you with or would you like to chat?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 43, 'total_tokens': 71, 'completion_time': 0.101818182, 'prompt_time': 0.005254975, 'queue_time': 0.33068305800000003, 'total_time': 0.107073157}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ca0059abb', 'finish_reason': 'stop', 'logprobs': None} id='run-2715548a-56ef-4bf0-9dff-e5ad6f5be625-0' usage_metadata={'input_tokens': 43, 'output_tokens': 28, 'total_tokens': 71}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = conversion.invoke('In one meter how many centimeter ?',temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='In 1 meter, there are 100 centimeters.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 146, 'total_tokens': 159, 'completion_time': 0.047272727, 'prompt_time': 0.010176014, 'queue_time': 0.26582554799999997, 'total_time': 0.057448741}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_0a4b7a8df3', 'finish_reason': 'stop', 'logprobs': None} id='run-178dc5f6-003f-475f-81fa-bbae9fa2a0f2-0' usage_metadata={'input_tokens': 146, 'output_tokens': 13, 'total_tokens': 159}\n"
     ]
    }
   ],
   "source": [
    "#print(memory.buffer)\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Azeem.\n"
     ]
    }
   ],
   "source": [
    "#memory.load_memory_variables({})\n",
    "response3 = conversion.invoke('what is my name',temp)\n",
    "print(response3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Azeem\n",
      "AI: Hello Azeem! It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "Human: Hi, my name is Azeem\n",
      "AI: Hello again Azeem! We've already met, but it's great to see you again. What's on your mind today? Want to talk about something in particular or just shoot the breeze?\n",
      "Human: In one meter how many centimeter ?\n",
      "AI: In 1 meter, there are 100 centimeters.\n",
      "Human: what is my name\n",
      "AI: Your name is Azeem.\n",
      "Human: what is my name\n",
      "AI: Your name is Azeem.\n"
     ]
    }
   ],
   "source": [
    "#memory = ConversationBufferMemory()\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"Welcome to Be Energy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Azeem\n",
      "AI: Hello Azeem! It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "Human: Hi, my name is Azeem\n",
      "AI: Hello again Azeem! We've already met, but it's great to see you again. What's on your mind today? Want to talk about something in particular or just shoot the breeze?\n",
      "Human: In one meter how many centimeter ?\n",
      "AI: In 1 meter, there are 100 centimeters.\n",
      "Human: what is my name\n",
      "AI: Your name is Azeem.\n",
      "Human: what is my name\n",
      "AI: Your name is Azeem.\n",
      "Human: Hi\n",
      "AI: Welcome to Be Energy\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Azeem\\nAI: Hello Azeem! It's nice to meet you. Is there something I can help you with or would you like to chat?\\nHuman: Hi, my name is Azeem\\nAI: Hello again Azeem! We've already met, but it's great to see you again. What's on your mind today? Want to talk about something in particular or just shoot the breeze?\\nHuman: In one meter how many centimeter ?\\nAI: In 1 meter, there are 100 centimeters.\\nHuman: what is my name\\nAI: Your name is Azeem.\\nHuman: what is my name\\nAI: Your name is Azeem.\\nHuman: Hi\\nAI: Welcome to Be Energy\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, I'm glad to be a part of your testing process, Azeem. It seems like everything is working as expected, and I'm responding to your \"hi\"s correctly. If you need to test anything else, feel free to do so!\n"
     ]
    }
   ],
   "source": [
    "result = conversion.invoke(\"i am testing my workging, so testing with hi only and check your response \", temp)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Buffer Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
